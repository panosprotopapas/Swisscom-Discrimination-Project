{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: {'User-Agent': 'Opera/9.80 (X11; Linux i686; Ubuntu/14.10) Presto/2.12.388 Version/12.16'}\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import discrimination\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Dense, Activation, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Get all texts and split into sexist and non-sexist. For each set, make a list with all sentences.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all texts and combine\n",
    "sex_txts = pickle.load(open(\"pickles2/sexist_new.p\", \"rb\"))\n",
    "nsex_txts = pickle.load(open(\"pickles2/nonsexist_new.p\", \"rb\"))\n",
    "texts_diary = pickle.load(open(\"pickles/texts_diary.p\", \"rb\"))\n",
    "texts_mydiary = pickle.load(open(\"pickles/texts_mydiary.p\", \"rb\"))\n",
    "texts_everydaysexism = pickle.load(open(\"pickles/texts_everydaysexism.p\", \"rb\"))\n",
    "# New texts come in tuples, with source info, not strings. Fix this\n",
    "sex_txts = [item[0] for item in sex_txts]\n",
    "nsex_txts = [item[0] for item in nsex_txts]\n",
    "# Remove /n from texts (as much as possible) \n",
    "sex_txts = [item.replace(\" /n \", \"\") for item in sex_txts]\n",
    "nsex_txts = [item.replace(\" /n \", \"\") for item in nsex_txts]\n",
    "# Add the old texts\n",
    "sex_txts.extend(texts_everydaysexism)\n",
    "nsex_txts.extend(texts_diary)\n",
    "nsex_txts.extend(texts_mydiary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into sentences\n",
    "sex_sentences = discrimination.texts.sentences_split(sex_txts)\n",
    "nsex_sentences = discrimination.texts.sentences_split(nsex_txts)\n",
    "# Save\n",
    "pickle.dump(sex_txts, open(\"pickles3/sex_txts.p\", \"wb\"))\n",
    "pickle.dump(nsex_txts, open(\"pickles3/nsex_txts.p\", \"wb\"))\n",
    "pickle.dump(sex_sentences, open(\"pickles3/sex_sentences.p\", \"wb\"))\n",
    "pickle.dump(nsex_sentences, open(\"pickles3/nsex_sentences.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Tokenize and check how the length distribution looks across the two groups.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize texts and remove stop-words\n",
    "sex_tkns = discrimination.texts.tokenize(sex_txts)\n",
    "nsex_tkns = discrimination.texts.tokenize(nsex_txts)\n",
    "# Remove stop-words a second time, in case some stopwords where misspelled.\n",
    "sex_tkns = discrimination.texts.remove_stopwords(sex_tkns)\n",
    "nsex_tkns = discrimination.texts.remove_stopwords(nsex_tkns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the average token length (words per token) in each group\n",
    "sex_wd_cnt = 0\n",
    "for tkn in sex_tkns:\n",
    "    sex_wd_cnt += len(tkn)\n",
    "nsex_wd_cnt = 0\n",
    "for tkn in nsex_tkns:\n",
    "    nsex_wd_cnt += len(tkn)\n",
    "\n",
    "print(\"Av. number of words-per-token in non-sexist texts is\", round(nsex_wd_cnt/len(nsex_tkns),1))\n",
    "print(\"Av. number of words-per-token in sexist texts is\", round(sex_wd_cnt/len(sex_tkns),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some graphs of the number of words per token for more information\n",
    "list_of_tokens = [sex_tkns, nsex_tkns]\n",
    "legend = [\"Sexist\", \"Non-Sexist\"]\n",
    "discrimination.texts.tokens_plot(list_of_tokens, (0,0.07), 135, [10,5], 90, legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the reason it appears that sexist texts have more words per token, when in reality they don't is due to the fatter right-tail of non-sexist tokens, for lengths larger than 100.\n",
    "\n",
    "However, since extremely few tokens have lengths larger than 128 words, will pad tokens at 128. At the same time I will randomly discard non-sexist tokens with very few words and with more than 100, in an effort to match the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Match the distribution of the two groups by discarding and splitting non-sexist texts, that are anyway more than the sexist ones.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "sex_txts = pickle.load(open(\"pickles3/sex_txts.p\", \"rb\"))\n",
    "nsex_txts = pickle.load(open(\"pickles3/nsex_txts.p\", \"rb\"))\n",
    "sex_sentences = pickle.load(open(\"pickles3/sex_sentences.p\", \"rb\"))\n",
    "nsex_sentences = pickle.load(open(\"pickles3/nsex_sentences.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split non-sexist sentences into two groups. Those with 50 or more sentneces, and the rest.\n",
    "a = []\n",
    "b = []\n",
    "for item in nsex_sentences:\n",
    "    if len(item) > 100:\n",
    "        a.append(item)\n",
    "    else:\n",
    "        b.append(item)\n",
    "# For the group with 40 or more sentences, split all items into 2 sentences.\n",
    "temp = []\n",
    "for item in a:\n",
    "    for i in range(0, len(item), 2):\n",
    "        temp.append(item[i: i+2])\n",
    "# Join the group to form the \"new\" non-sexist sentences\n",
    "nsex_sentences = b\n",
    "nsex_sentences.extend(temp)\n",
    "# Make the sentences into texts again\n",
    "texts = []\n",
    "for item in nsex_sentences:\n",
    "    text = \" \".join(item)\n",
    "    texts.append(text)\n",
    "# These are the \"new\" non-sexist texts\n",
    "nsex_txts = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize texts and remove stop-words\n",
    "sex_tkns = discrimination.texts.tokenize(sex_txts)\n",
    "nsex_tkns = discrimination.texts.tokenize(nsex_txts)\n",
    "# Spell-check tokens. (Notificaiton every 20.000 tokens)\n",
    "sex_tkns = discrimination.texts.spellcheck_tokens(sex_tkns)\n",
    "nsex_tkns = discrimination.texts.spellcheck_tokens(nsex_tkns)\n",
    "# Remove stop-words a second time, in case some stopwords where misspelled.\n",
    "sex_tkns = discrimination.texts.remove_stopwords(sex_tkns)\n",
    "nsex_tkns = discrimination.texts.remove_stopwords(nsex_tkns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard all tokens with length larger than 128 from both groups\n",
    "sex_tkns = [tkn for tkn in sex_tkns if len(tkn) <=128]\n",
    "nsex_tkns = [tkn for tkn in nsex_tkns if len(tkn) <=128]\n",
    "\n",
    "# With a probability of 3% keep non-sexist tokens with a length of 1,2,3, and 4\n",
    "a = [tkn for tkn in nsex_tkns if len(tkn) <= 3 and random.random() < 0.03]\n",
    "# With a probability of 10% keep non-sexist tokens with a length of 4\n",
    "b = [tkn for tkn in nsex_tkns if len(tkn) == 4 and random.random() < 0.1]\n",
    "# With a probability of 20% keep non-sexist tokens with a length of 5\n",
    "c = [tkn for tkn in nsex_tkns if len(tkn) == 5 and random.random() < 0.2]\n",
    "# With a probability of 40% keep non-sexist tokens with a length of 6\n",
    "d = [tkn for tkn in nsex_tkns if len(tkn) == 6 and random.random() < 0.4]\n",
    "# With a probability of 60% keep non-sexist tokens with a length of 7\n",
    "e = [tkn for tkn in nsex_tkns if len(tkn) == 7 and random.random() < 0.6]\n",
    "# With a probability of 70% keep non-sexist tokens with a length of 8\n",
    "f = [tkn for tkn in nsex_tkns if len(tkn) == 8 and random.random() < 0.7]\n",
    "# Keep all non-sexist tokens with a length larger than 8\n",
    "nsex_tkns = [tkn for tkn in nsex_tkns if len(tkn) > 8]\n",
    "\n",
    "# Combine all\n",
    "nsex_tkns.extend(a)\n",
    "nsex_tkns.extend(b)\n",
    "nsex_tkns.extend(c)\n",
    "nsex_tkns.extend(d)\n",
    "nsex_tkns.extend(e)\n",
    "nsex_tkns.extend(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a probability of 30% separate non-sexist tokens with a length between 15 and 25\n",
    "sep1 = []\n",
    "sep2 = []\n",
    "for tkn in nsex_tkns:\n",
    "    if 15 <= len(tkn) <= 25 and random.random() < 0.3:\n",
    "        sep1.append(tkn)\n",
    "    else:\n",
    "        sep2.append(tkn)\n",
    "a = sep2\n",
    "# Join each pair of the separated tokens into one larger token.\n",
    "b = []\n",
    "for i in range(0, len(sep1) - 1, 2):\n",
    "    tkn = sep1[i]\n",
    "    tkn.extend(sep1[i+1])\n",
    "    b.append(tkn)\n",
    "# Form the new non-sexist tokens\n",
    "nsex_tkns = a\n",
    "nsex_tkns.extend(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a probability of 20% separate non-sexist tokens with a length between 26 and 42\n",
    "sep1 = []\n",
    "sep2 = []\n",
    "for tkn in nsex_tkns:\n",
    "    if 26 <= len(tkn) <= 42 and random.random() < 0.2:\n",
    "        sep1.append(tkn)\n",
    "    else:\n",
    "        sep2.append(tkn)\n",
    "a = sep2\n",
    "# Join each pair of the separated tokens into one larger token.\n",
    "b = []\n",
    "for i in range(0, len(sep1) - 1, 2):\n",
    "    tkn = sep1[i]\n",
    "    tkn.extend(sep1[i+1])\n",
    "    b.append(tkn)\n",
    "# Form the new non-sexist tokens\n",
    "nsex_tkns = a\n",
    "nsex_tkns.extend(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a probability of 22% separate non-sexist tokens with a length of 7\n",
    "sep1 = []\n",
    "sep2 = []\n",
    "for tkn in nsex_tkns:\n",
    "    if len(tkn) == 7 and random.random() < 0.22:\n",
    "        sep2.append(tkn)\n",
    "    else:\n",
    "        sep1.append(tkn)\n",
    "nsex_tkns = sep1\n",
    "# With a probability of 18% separate non-sexist tokens with a length of 8\n",
    "sep1 = []\n",
    "sep3 = []\n",
    "for tkn in nsex_tkns:\n",
    "    if len(tkn) == 8 and random.random() < 0.18:\n",
    "        sep3.append(tkn)\n",
    "    else:\n",
    "        sep1.append(tkn)\n",
    "nsex_tkns = sep1\n",
    "# With a probability of 30% separate non-sexist tokens with a length of 9\n",
    "sep1 = []\n",
    "sep4 = []\n",
    "for tkn in nsex_tkns:\n",
    "    if len(tkn) == 9 and random.random() < 0.3:\n",
    "        sep4.append(tkn)\n",
    "    else:\n",
    "        sep1.append(tkn)\n",
    "nsex_tkns = sep1\n",
    "# With a probability of 14% separate non-sexist tokens with a length of 10\n",
    "sep1 = []\n",
    "sep5 = []\n",
    "for tkn in nsex_tkns:\n",
    "    if len(tkn) == 10 and random.random() < 0.14:\n",
    "        sep5.append(tkn)\n",
    "    else:\n",
    "        sep1.append(tkn)\n",
    "nsex_tkns = sep1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the separated tokens in a new variable and shuffle it\n",
    "separated = sep2.copy()\n",
    "separated.extend(sep3)\n",
    "separated.extend(sep4)\n",
    "separated.extend(sep5)\n",
    "# Average token length is 8.5 so after randomizing join every 6 tokens together and add to the nsex_tkns\n",
    "random.shuffle(separated)\n",
    "new = []\n",
    "for i in range(0, len(separated) - 5, 6):\n",
    "    tkn = separated[i]\n",
    "    tkn.extend(separated[i+1])\n",
    "    tkn.extend(separated[i+2])\n",
    "    tkn.extend(separated[i+3])\n",
    "    tkn.extend(separated[i+4])\n",
    "    tkn.extend(separated[i+5])\n",
    "    new.append(tkn)\n",
    "nsex_tkns.extend(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some graphs of the number of words per token for more information\n",
    "list_of_tokens = [sex_tkns, nsex_tkns]\n",
    "legend = [\"Sexist\", \"Non-Sexist\"]\n",
    "discrimination.texts.tokens_plot(list_of_tokens, (0,0.06), 128, [10,5], 90, legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "pickle.dump(sex_tkns, open(\"pickles3/sex_tkns.p\", \"wb\"))\n",
    "pickle.dump(nsex_tkns, open(\"pickles3/nsex_tkns.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### NN preparation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokens\n",
    "sex_tkns = pickle.load(open(\"pickles3/sex_tkns.p\", \"rb\"))\n",
    "nsex_tkns = pickle.load(open(\"pickles3/nsex_tkns.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the length of sex_tkns by randomly dropping nsex_tkns\n",
    "nsex_tkns = random.sample(nsex_tkns, len(sex_tkns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokens back to text for Keras\n",
    "keras_txts = []\n",
    "for tkn in itertools.chain(sex_tkns, nsex_tkns):\n",
    "    txt = \" \".join(tkn)     \n",
    "    keras_txts.append(txt)\n",
    "    \n",
    "# Create labels\n",
    "keras_labels = np.zeros(len(keras_txts))\n",
    "keras_labels[:len(sex_tkns)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing - Sequencing\n",
    "tokenizer = Tokenizer(lower = False)\n",
    "tokenizer.fit_on_texts(keras_txts)\n",
    "sequences = tokenizer.texts_to_sequences(keras_txts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Create and shuffle data and labels. MAXLEN = 128 \n",
    "data = pad_sequences(sequences, maxlen=128)\n",
    "labels = np.asarray(keras_labels)\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "# Split 80-20\n",
    "nb_validation_samples = int(0.2 * data.shape[0])\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the GloVe word embeddings\n",
    "glove_dir = \"glove/\"\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, \"glove.42B.300d.txt\"))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embedding matrix\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "# Delete the embeddings index as it's no longer needed.\n",
    "del embeddings_index\n",
    "# Create the embedding layer. INPUT LENGTH 128\n",
    "embedding_layer = Embedding(len(word_index) + 1, 300, input_length=128,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### NN setup and compilation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 128, 300)          43193700  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 38400)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 38400)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               9830656   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 53,061,413\n",
      "Trainable params: 9,867,713\n",
      "Non-trainable params: 43,193,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation=\"relu\", kernel_regularizer = regularizers.l2(0.001)))\n",
    "model.add(Dense(128, activation=\"relu\", kernel_regularizer = regularizers.l2(0.001)))\n",
    "model.add(Dense(32, activation=\"relu\", kernel_regularizer = regularizers.l2(0.001)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 325957 samples, validate on 81489 samples\n",
      "Epoch 1/3\n",
      "325957/325957 [==============================] - 231s 709us/step - loss: 0.3929 - acc: 0.9199 - val_loss: 0.2682 - val_acc: 0.9420\n",
      "Epoch 2/3\n",
      "325957/325957 [==============================] - 281s 863us/step - loss: 0.2743 - acc: 0.9319 - val_loss: 0.2279 - val_acc: 0.9469\n",
      "Epoch 3/3\n",
      "325957/325957 [==============================] - 277s 848us/step - loss: 0.2639 - acc: 0.9344 - val_loss: 0.2269 - val_acc: 0.9483\n"
     ]
    }
   ],
   "source": [
    "# Compilation\n",
    "model.compile(optimizer = \"Adam\",\n",
    "              loss = \"binary_crossentropy\",\n",
    "              metrics = [\"acc\"])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs = 3,\n",
    "                    batch_size = 256,\n",
    "                    validation_data = (x_val, y_val))\n",
    "\n",
    "# Save model weights\n",
    "model.save_weights(\"pickles3/model3b2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights\n",
    "model.load_weights(\"pickles3/model3b2.h5\")\n",
    "# Predictions\n",
    "predictions = model.predict(data)\n",
    "# Save\n",
    "pickle.dump(predictions, open(\"pickles3/predictions2.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives account for 94.9% or 47.5% of the total (sexist texts labelled as sexist).\n",
      "False positives account for 5.1% or 2.5% of the total (sexist texts labelled as non-sexist).\n",
      "True negatives account for 95.8% or 47.9% of the total (non-sexist texts labelled as non-sexist).\n",
      "False negatives account for 4.2% or 2.1% of the total (non-sexist texts labelled as sexist).\n"
     ]
    }
   ],
   "source": [
    "# Create a predicted labels list\n",
    "labels_predicted = []\n",
    "for prediction in predictions:\n",
    "    labels_predicted.append( round(prediction[0]) )\n",
    "# Calculate the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "CF = confusion_matrix(labels, labels_predicted)\n",
    "#\"Disentangle\" the matrix\n",
    "TN = round((CF[0,0] / sum(CF[0,:])) * 100, 1)\n",
    "FN = round((CF[0,1] / sum(CF[0,:])) * 100, 1)\n",
    "TP = round((CF[1,1] / sum(CF[1,:])) * 100, 1)\n",
    "FP = round((CF[1,0] / sum(CF[1,:])) * 100, 1)\n",
    "GTN = round((CF[0,0] / (sum(CF[0,:]) + sum(CF[1,:]))) * 100, 1)\n",
    "GFN = round((CF[0,1] / (sum(CF[0,:]) + sum(CF[1,:]))) * 100, 1)\n",
    "GTP = round((CF[1,1] / (sum(CF[0,:]) + sum(CF[1,:]))) * 100, 1)\n",
    "GFP = round((CF[1,0] / (sum(CF[0,:]) + sum(CF[1,:]))) * 100, 1)\n",
    "# Print the results\n",
    "print(\"True positives account for \"+str(TP)+\"% or \"+str(GTP)+\"% of the total (sexist texts labelled as sexist).\")\n",
    "print(\"False positives account for \"+str(FP)+\"% or \"+str(GFP)+\"% of the total (sexist texts labelled as non-sexist).\")\n",
    "print(\"True negatives account for \"+str(TN)+\"% or \"+str(GTN)+\"% of the total (non-sexist texts labelled as non-sexist).\")\n",
    "print(\"False negatives account for \"+str(FN)+\"% or \"+str(GFN)+\"% of the total (non-sexist texts labelled as sexist).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0186b929b5a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtest_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the network\n",
    "test = ['''Women''']\n",
    "\n",
    "# Convert the test phrase to lowercase, tokenize, spellcheck, remove stopwords. \n",
    "test = discrimination.texts.lowercase(test)\n",
    "test = discrimination.texts.tokenize(test)\n",
    "test = discrimination.texts.spellcheck_tokens(test)\n",
    "test = discrimination.texts.remove_stopwords(test)\n",
    "\n",
    "# Convert the token back to text, sequence it, pad it, feed it into the model.\n",
    "text = \"\"\n",
    "for item in test:\n",
    "    for word in item:\n",
    "        text += word + \" \"   \n",
    "test_sequence = tokenizer.texts_to_sequences([text])\n",
    "\n",
    "x_test = pad_sequences(test_sequence, maxlen=128)\n",
    "model.load_weights(\"pickles3/model3b2.h5\")\n",
    "# Make the output look pretty... because it deserves it.\n",
    "str(round(model.predict(x_test)[0,0]*100,0))[:-2] + \"% sexist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
