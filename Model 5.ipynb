{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import discrimination\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Dense, Activation, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Split sexist texts into sentences and tokenize\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load texts and only keep texts (from tuples loaded)\n",
    "sex_txts = pickle.load(open(\"pickles2/sexist_new.p\", \"rb\"))\n",
    "sex_txts = [txt[0] for txt in sex_txts]\n",
    "# Split into a list of sentences\n",
    "sex_temp = discrimination.texts.sentences_split(sex_txts)\n",
    "# Combine all lists in one big list of sentences\n",
    "sex_sentences = []\n",
    "for item in sex_temp:\n",
    "    for sentence in item:\n",
    "        sex_sentences.append(sentence)\n",
    "# Uncensore bad words!\n",
    "for j in range(5):\n",
    "    for i, item in enumerate(sex_sentences):\n",
    "        if \"c~~~\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"c~~~\", \"cunt\")\n",
    "        if \"s~~~\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"s~~~\", \"shit\")\n",
    "        if \"f~~~\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"f~~~\", \"fuck\")\n",
    "        if \"p~~~\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"p~~~\", \"piss\")\n",
    "        if \"t~~~\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"t~~~\", \"tits\")\n",
    "        if \"b~~~~\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"b~~~~\", \"balls\")\n",
    "        if \"fuck~~\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"fuck~~\", \"fucker\")\n",
    "        if \"f~~\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"f~~\", \"fag\")       \n",
    "for j in range(5):\n",
    "    for i, item in enumerate(sex_sentences):\n",
    "        if \"c***\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"c***\", \"cunt\")\n",
    "        if \"s***\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"s***\", \"shit\")\n",
    "        if \"f***\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"f***\", \"fuck\")\n",
    "        if \"p***\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"p***\", \"piss\")\n",
    "        if \"t***\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"t***\", \"tits\")\n",
    "        if \"b****\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"b****\", \"balls\")\n",
    "        if \"fuck**\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"fuck**\", \"fucker\")\n",
    "        if \"f****\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"f****\", \"fucking\")        \n",
    "        if \"a**\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"a**\", \"ass\")  \n",
    "        if \"s**t\" in item:\n",
    "            sex_sentences[i] =  item.replace(\"s**t\", \"shit\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 tokens spell-checked.\n",
      "200000 tokens spell-checked.\n",
      "300000 tokens spell-checked.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize sentences and remove stop-words\n",
    "sex_tokens = discrimination.texts.tokenize(sex_sentences)\n",
    "# Spell-check tokens. This actually takes some time (not too much) so there's a timer every 20.000 tokens checked.\n",
    "sex_tokens = discrimination.texts.spellcheck_tokens(sex_tokens)\n",
    "# Remove stop-words a second time, in case some stopwords where misspelled.\n",
    "sex_tokens = discrimination.texts.remove_stopwords(sex_tokens)\n",
    "# Remove empty tokens and the relevant sentences.\n",
    "temp_tokens = sex_tokens.copy()\n",
    "temp_sentences = sex_sentences.copy()\n",
    "sex_tokens.clear()\n",
    "sex_sentences.clear()\n",
    "for i, tkn in enumerate(temp_tokens):\n",
    "    if len(tkn) != 0:\n",
    "        sex_tokens.append(tkn)\n",
    "        sex_sentences.append(temp_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350792 sexist sentences.\n"
     ]
    }
   ],
   "source": [
    "print(len(sex_tokens),\"sexist sentences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "pickle.dump(sex_tokens, open(\"pickles5/sex_tokens.p\", \"wb\"))\n",
    "pickle.dump(sex_sentences, open(\"pickles5/sex_sentences.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" i mean i understand people against misandry but what's wrong with equality?\",\n",
       " \" and i'm not a feminist because this title promotes female 'equality' but they never talk about men equality.\",\n",
       " 'this is the most sexist thing i\\'ve seen i don\\'t apply to any of those things this video is offensive if you think you\\'re \"feminist\" and want equality, then go be a trash man or build something with you\\'re own two hands, go do something that women don\\'t traditionally do, then say you\\'re a feminist',\n",
       " ' so to hide their grandiose expectations, they paint half of men as slobs who are not even worthy of causal sex!  /n if you are an ugly, confused man.',\n",
       " '\"\\xa0it is certainly the case that some feminists are sometimes annoying, over-dramatic, wrong, etc.',\n",
       " 'how does this situation have anything to do with what we are discussing?',\n",
       " '  /n however, i do not, as again, blame women, or feminists.',\n",
       " ' who the fuck veers their truck off the road just to yell expletives at a fat bearded man?',\n",
       " 'is the dog barking woof, or rape?',\n",
       " \" yes, women are used in comercials/etc more often, but that doesn't mean men don't suffer from objectification and women being just plain shallow.\"]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(sex_sentences, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
